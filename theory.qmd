```{r}
#| label: theory-setup
#| include: false

library(tidyverse)
```

# Theory

## Statistical learning

In short, statistical learning is the process of using statistical methods and mathematical models to understand data [@islr, p. 1]. This process can be used to predict values given a set of variables, or to gain a better understanding of how those variables relate to the wanted value, also called *inference*. Often, the goal might be both prediction and inference.

Given that we wish to predict the response value $Y$ from one or more variables, or predictors, $X$, this can be expressed in a general form as @eq-rel.

$$ Y = f(X) + \epsilon $$ {#eq-rel}

Here, $f$ is some kind of transformation made on $X$ in order for it to help us estimate $Y$, end $\epsilon$ is an *error term* which is unknown, and assumed to be normally distributed with a mean of 0. We need $\epsilon$ because our model will never be able to take into account for every little variable that might influence or prediction.

One of the simplest, yet most powerful, methods of statistical learning is *linear regression*.

## Linear regression

### Simple linear regression

At the heart of linear regression lies the equation of the straight line (@eq-line)

$$ y = b + mx$$ {#eq-line}

where $b$ denotes the *intercept* where the line crosses the y-axis, and $m$ denotes the *slope* of the line.

In simple linear regression we assume that the relationship between the response variable $Y$ and the independent variable $X$ is approximately linear, which can be expressed as (@eq-linreg-1). [@islr, p. 61]

$$ Y \approx \beta_0 + \beta_1 X$$ {#eq-linreg-1}

Here, $\beta_0$ denotes the intercept and $\beta_1$ denotes the slope of the line. Using training data, we can estimate the *coefficients* $\hat{\beta_0}$ and $\hat{\beta_1}$ and predict a certain value of $Y$ by computing 

$$ \hat{y} = \hat{\beta_0} + \hat{\beta_1} x. $$ {#eq-linreg-2}

#### Estimating coefficients

The coefficients can be estimated using a number of approaches, but the most common method is the *least squares* criterion.

The goal is to find values for $\beta_0$ and $\beta_1$ such that the difference between the observed response value and our predicted response value, the *residual*, is as small as possible. The *i*th residual $e_i$ can be expressed as $e_i = y_i - \hat{y}_i$. Given $n$ observations in our training data, the *residual sum of squares* (RSS) is defined as

$$ RSS = e^2_1 + e^2_2 + \ldots + e^2_n, $$ {#eq-rss-1} or

$$ RSS = \sum_{i = 1}^{n}(y_i - \hat{y}_i)^2. $$ {#eq-rss-2}

The least squares method then chooses $\beta_0$ and $\beta_1$ to minimize the RSS.

```{r}
#| echo: false
#| label: fig-rss
#| fig-cap: "Linear regression on simulated data. The red line shows the true relationship $f(X) = 3+5X$, and the blue line is the least squares estimate for f(X) based on the generated data."


set.seed(42)

x <- runif(100, min = -2, max = 2)
e <- rnorm(100, mean = 0, sd = 5)
y <- 3 + 5 * x + e

ggplot(mapping = aes(x = x, y = y)) + 
    geom_point() +
    geom_smooth(
      method = "lm", 
      formula = y ~ x, 
      col = "blue", 
      alpha = .5, 
      linewidth = 1, 
      se = FALSE) +
    geom_line(
      aes(x = x, y = 2 + 3 * x), 
      col = "red", 
      linewidth = 1, 
      alpha = .5) +
    theme_bw()
```
#### Evaluating model performance

To assess how well a model fits the data, two measures are commonly used: the *residual standard error* ($RSE$), and the $R^2$ statistic.

It is rarely the case that a models captures every thinkable variable that affects the outcome. Therefore, the error term $\epsilon$ from @eq-rel is present in our model. @eq-linreg-1 can be subsistuted for the general function $f$, which gives us @eq-linreg-3:

$$ Y = \beta_0 + \beta_1 X + \epsilon. $$ {#eq-linreg-3}

##### The residual standard error

The $RSE$ is an estimate of the standard deviation of $\epsilon$ [@islr, p. 69] and is computed by

$$ RSE = \sqrt{\dfrac{1}{n - 2}RSS}. $$ {#eq-rse}

If the predicted values of the model are close to the observed values, the $RSE$ will be small and the model fits the data well.

##### The $R^2$ statistic

The $RSE$ is measured in the units of $Y$. This makes interpreting what a good value of the $RSE$ is hard. [@islr, p. 70]. The $R^2$ statistic, on the other hand, is a *proportion*, and as such always takes on a value between 0 and 1.

The $R^2$ statistic describes how much of the total variance in the response $Y$ that can be explained by using $X$ as a predictor. The formula used is seen in @eq-r2.

$$ R^2 = \dfrac{TSS-RSS}{TSS} = 1 - \dfrac{RSS}{TSS} $$ {#eq-r2}

$TSS = \sum{(y_i - \bar{y})}$ is the *total sum of squares* and RSS is defined in @eq-rss-2. While $R^2$ is independent of the units of $Y$, it can still be hard to determine what constitutes a good value of $R^2$. This depends on the problem at hand as different domains handle different kinds of data, with different properties and relationships.

### Multiple linear regression
So far we have been using a single predictor $X_1$ to predict the response $Y$. In *multiple linear regression*, additional predictors are added to form the model

$$ Y = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \ldots + \beta_p X_p + \epsilon $$ {#eq-multi-linreg-1}

where $X_j$ represents the *j*th predictor, and $\beta_j$ represents the effect of $X_j$ on $Y$, or, in other words, the *average* effect on $Y$ on a one unit increase in $X_j$, given that *all other predictors remain fixed*.

#### Potential problems

In *Introduction to Statistical Learning*, James and co-authors list six of the most common potential problems when fitting linear regression models [@islr, p. 93]. These are:

1. Non-linearity of the response-predictor relationships.
2. Correlation of error terms.
3. Non-constant variance of error terms.
4. Outliers.
5. High-leverage points.
6. Collinearity.

## Evaluating models
The theory behind evaluating model performance. Cross validation.

### Train/test data
The reason behind splitting data.

### Evaluation metrics
Statistical methods, RMSE...

## Feature selection
Significance. Statistical methods vs. domain knowledge. [@hyndman]